# Wednesday - June 11th

## Daily Overview

- Start Time: 9:40AM
- End Time:

## Today's Priorities

1. Get ACE Judge implementation working online and offline

## Tasks & Progress

### Completed

- ACE
  - ACE judge implemented and test run working; (issue)[https://github.com/Shopify/support-data/issues/2357] closed
  - Results in `sdp-stg-commercial.support_llmeval.sba_ace_v1`
  - Sample results plotted and shared in (slack)[https://shopify.enterprise.slack.com/archives/C08STPH3EET/p1749675370517469]

### In Progress

- ACE
  - Create 1-page writeup
- Classification Set Analysis
  - Create 1-page writeup
- Fill out internship log
  - Write update on Summit and progress
  - Include anything pushed
- Technical Onboarding
  - Current status: Ruby (OOP)

### Inventory

- Watch recording of LLM Eval Standup
  - Priority: Low
- Review [MLE best practices](https://vault.shopify.io/page/ML-Best-Practices~cGm2.md)
  - Priority: Med
- Review remaining slides for next meeting with Delali
  - Prioriy: Med
- Review [LLM evaluation](https://www.oreilly.com/radar/a-field-guide-to-rapidly-improving-ai-products/) and [RAG](https://aws.amazon.com/what-is/retrieval-augmented-generation/)
  - Prioriy: Low
- Learn about [monorail](https://vault.shopify.io/page/Monorail~1rHm.md)
  - Priority: Low
- Learn about [LLM eval project](https://vault.shopify.io/gsd/proposals/9ETAno) for Q2
  - Priority: Med
- Read through [QAU documentation](https://docs.google.com/document/d/1sfNOpJTmoNoyYs_lIkPMgTLlii61nWy_ygC1sb-_zyU/edit?tab=t.0#heading=h.gdqdy9yvqkj5)
  - Priority: Low
- Message for coffee chats: Curtis, Cody, Diego
  - Priority: Low
- Read [autocomplete docs](https://docs.google.com/document/d/1FN84YruPEcKwwMPmkU9P-xOPz7Lgp1BWe2QFdtg7sT0/edit?tab=t.d4w7ie4tl9vq#heading=h.9dxbpvikj18m)
  - Priority: Med
- Read documentation on [major changes](https://docs.google.com/document/d/1WyIaUrdqcneD_kY8aPgpCv-8qtfBg9CSzIr_ka-47b8/edit?tab=t.0#heading=h.8ocwxlp3fls8)
  - Priority: Low
- Read [A Survey on LLM-as-a-Judge](https://arxiv.org/pdf/2411.15594)
  - Priority: Low
- Set up coffee chat with Topher Bullock to discuss MCP implementation for more agentic support assistants
  - Priority: Low

## Meetings & Discussions

### Eugene/Delali 1:1

- Time: 10:00AM - 10:15AM
- Participants: Delali
- Key Points:
  - Worked on SBA interactions, SBA classifications, now SBA ACE
  - Talked about feeling slow and demoralized from unexpected results
    - Calvin suggested timeboxing
  - Will focus on LLM judge this week and next week
  - Delali wants me to explore different projects that other MLEs are working on
  - My progress has been good: working hard and communicating well

### Support ML Science

- Time: 1:00PM - 1:45PM
- Participants: Team
- Key Points:
  - Fedor working on improving RAG to include more sources (may include multimodal) from internal and external sources
    - Exploring using Perplexity along the pipeline to provide users with another avenue for answers (Perplexity includes external sources such as reddit)

### LLM Eval Standup

- Time: 2:30PM - 2:50PM
- Participants: Calvin, Peter
- Key Points:

  - Calvin working with eng team to push this into support-core and run in productions
    - Alot of refactoring and improvements
    - yaml file for config instead of passing in cli params
  - After speaking with Peter: online_evals will be scheduled to run with yesterday’s interactions (new sql query which get stored in a BigQuery table). Downstream task will compute relevant metrics (avg score) using sql query (../sql/shop_buyer_help_assistant/daily_classification_accuracy_metrics.sql) and display in dashboard.
  - What is the workflow for offline_evals? For example, if I want to compare two prompts, how do I specify which prompt and ensure that they’re running at the same time/same data?
    - We can specify prompt in yaml file and they will most likely be working on csv as source.
  - Modified the prompt to only output scores for each dimension and final score is done manually → no advantage to using an LLM for calculations → allows us to finetune the weighting
  - Some tweaks to framework
    - Allow selection of judge in cli
    - Masking for judge selection
    - Date objects were returning typeError
  - BotInteractions are evaluated all at once and send to SQL table all at once. Improvement would be to periodically send results to SQL tables; Free up memory; Prevent loss if evaluation is stopped.
    - Good idea if calls start to bottleneck but complication with BigQuery rate limiting; Not a priority right now.

- Action Items:
  - [x] Compute and share ACE judge metrics

## Tomorrow's Plan

- Clear backlog
