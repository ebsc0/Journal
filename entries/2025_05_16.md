# Friday - May 16th

## Daily Overview
- Start Time: 9:05AM
- End Time: 5:36PM

## Today's Priorities
1. Write statistical findings
2. PP session with Kasey
3. Complete technical onboarding

## Tasks & Progress
### Completed
- Statistical analysis of LLM Eval
  - Compute accuracy with human label as ground truth
  - Include metric and provide any insights gained in findings doc
  - Perform classification report (scikit-learn)
  - Use Cohen's Kappa to see if agreement is statistically significant
- PP session with Kasey
  - HCA bots and an brief explanation on the business decisions governing their development

### In Progress
- Update [Internship Logs](https://docs.google.com/document/d/1OP6eWeH_pp2Jss-_1qxGwVFwl2ml43cihyqPkZvf6FU/edit?tab=t.u0of4776rhm3)
- Statistical analysis of LLM Eval
  - Write a 1-page findings doc
  - Look into data on where it disagrees to find insights
- Technical Onboarding
  - Current status: Ruby (OOP)
- PP session prep
  - Shannon - 05.21

### Inventory
- Create Brag Doc
  - Priority: High
- Review [MLE best practices](https://vault.shopify.io/page/ML-Best-Practices~cGm2.md)
  - Priority: Med
- Review remaining slides for next meeting with Delali
  - Prioriy: Med
- Review [LLM evaluation](https://www.oreilly.com/radar/a-field-guide-to-rapidly-improving-ai-products/) and [RAG](https://aws.amazon.com/what-is/retrieval-augmented-generation/)
  - Prioriy: Low
- Learn about [monorail](https://vault.shopify.io/page/Monorail~1rHm.md)
  - Priority: Low
- Learn about [LLM eval project](https://vault.shopify.io/gsd/proposals/9ETAno) for Q2
  - Priority: Med
- Play with the BigQuery console
  - Priority: Low
- Read through [QAU documentation](https://docs.google.com/document/d/1sfNOpJTmoNoyYs_lIkPMgTLlii61nWy_ygC1sb-_zyU/edit?tab=t.0#heading=h.gdqdy9yvqkj5)
  - Priority: Low
- Read about [PII](https://vault.shopify.io/page/Personally-identifiable-information-PII~4631.md)
  - Priority: Low
- Message for coffee chats: Curtis, Cody, Diego
  - Priority: Low
- Read [autocomplete docs](https://docs.google.com/document/d/1FN84YruPEcKwwMPmkU9P-xOPz7Lgp1BWe2QFdtg7sT0/edit?tab=t.d4w7ie4tl9vq#heading=h.9dxbpvikj18m)
  - Priority: Med
- Read documentation on [major changes](https://docs.google.com/document/d/1WyIaUrdqcneD_kY8aPgpCv-8qtfBg9CSzIr_ka-47b8/edit?tab=t.0#heading=h.8ocwxlp3fls8)
  - Priority: Low
- Reevaluate using request_id and inquiry_type
  - Priority: Med

## Meetings & Discussions
### Daily Standup
- Time: 10:00AM - 10:20AM
- Participants: Calvin
- Key Points:
  - Calvin is working on evaluating AI Search
    - Trying to find cases where a user used AI Search then HCA with the intuition that they could not resolve their problem
    - We want to differentiate between similar queries and different queries
      - Ex. a person might ask for cheapest shipping options on AI Search and then fastest shipping options on HCA -> doesn't mean that AI Search failed
      - Need human labeling to evaluate where it fails and where it doesn't to find areas that AI Search needs to improve
- Action Items:
  - [x] Perform classification report (scikit-learn)
  - [x] Use Cohen's Kappa to see if agreement is statistically significant
  - [ ] Look into data on where it disagrees to find insights
  - [ ] Explore hypothesis of performance increasing with model complexity

### Pair Programming
- Time: 10:30AM - 11:30AM
- Participants: Kasey
- Key Points:
  - Why does the Effort counter go up when the user only asks for an advisor? What is the threshold?
    - It guages frustration in which business has instructed to just send them to an advisor
  - Should the HCA respond to each off-topic query? Cost?
    - DDOS security is not our area
  - Is this all done by LLM? Have we tried clustering using encodings?
    - Cost reduction is not a priority so hasn't been assigned (previous work done by curtis) and may not be impactful if business decisions change to remove the classification bot entirely
  - If each message is classified individually, how is context preserved? Is a message first classified, then another agent can see the entire history?
    - Context is given to funnelled agent and agent is unable to message twice in row
  - A good area to look into is an agent that can analyze the messages for complexity, ambiguity, how challenging it is, etc... to route it to a larger model etc...
  - Rundown of architecture
    - There are ~10 core components for the HCA bot: effort counter, canned responses, core prompts, core logic, etc...
    - Many products at Shopify want their own bot
    - To save on time and cost, we copy some of the core componenets and build their bot
    - Proposal is to use one bot for each product so that no bot is worse or better and development process is streamlined
      - We can offer a better experience by allowing a user to ask about Shopify and Shop within the same UI instead of them having to go to a different chat and reexplaining their problem
      - This could work by offering different prompts and resources to the various bots
    - But different product teams may want different behaviour
      - Ex. HCA allows for tickets to human advisors; Shop bot gives an email to send problem
      - Who has ownership? If bots are continuously changing by product, we're back to where we started
    - Kasey's idea is to have a UI where different agents can all exists and so a user can ask the Shop bot and HCA within the same chat session
      - Similar to LibreChat -> Imagine being on a 3-way call with the Shop bot and HCA where the Shop bot clarifies and asks the question to HCA for you
  - Kasey shipped a major change May 7th
  - A better way to evaluate would be to also see if the degredation of response was from misclassification or poor LLM understanding
    - en.yml in support-core for canned responses
    - app/agents/tools/shop/support_request.rb
      - Support request is different than other classifications and is further classified for more deflection opportunities
    - app/agents/prompts/bots/buyer/shop_buyer_agent/output_instructions.txt.erb
    - ```
      select * from `shopify-dw.support.shop_buyer_assistant_inquiry_type_classifications`
      where session_token = ‘47f08535-7e24-4be5-a74b-bd6ccc8d4ef3’
      order by event_timestamp`
      ```
- Action Items:
  - [ ] Read documentation on [major changes](https://docs.google.com/document/d/1WyIaUrdqcneD_kY8aPgpCv-8qtfBg9CSzIr_ka-47b8/edit?tab=t.0#heading=h.8ocwxlp3fls8)
  - [ ] Reevaluate using request_id and inquiry_type

### Support ML Science
- Time: 1:00PM - 2:00PM
- Participants: Team
- Key Points:
  - GoldenV2 dataset
  - Kasey - anti-chunking
    - 4o to 4.1-mini
    - Larger context window
    - Chunking: RAG 30 “chunk” of docs
    - More context improves performance
    - No chunking: Instead of snippets, full docs
    - 4.1-mini on Shop bot and Biliing agent
    - Is performance symmetric across all types of questions?
    - More complex → better models
    - Might increase tech-debt to diversify model offerings
    - Maybe offer for only top 10-5% of complex questions to best model with chain of thought etc…
    - Assumption is that 4.1-mini is better irregardless of more context
    - Retrieval is still on chunk level which serve as indicators as to what docs get included
    - Not worth to compute embeddings of the full docs
  - Peter - Autocomplete
    - Give search suggestions in AI Search
    - Important because AI Search needs to respond in 1-shot
    - Better understand user intent
    - Take disambiguation dataset from HCA 
    - Risk with PII
    - Filter PII info with LLM flags etc
    - Deduplication logic
    - Consolidate similar queries to clusters to better respond
    - Manual upload instead of automatic
    - To prevent PII leakage
    - ~15k questions
    - Weights for more asked questions used in retrieval
  - Calvin - LLM Eval
    - AI Search is good → Hard to find failure cases → Don’t know where to improve
- Action Items:
  - [ ] Read [autocomplete docs](https://docs.google.com/document/d/1FN84YruPEcKwwMPmkU9P-xOPz7Lgp1BWe2QFdtg7sT0/edit?tab=t.d4w7ie4tl9vq#heading=h.9dxbpvikj18m)

## Technical Notes
- [Union find](https://en.wikipedia.org/wiki/Disjoint-set_data_structure)

## Learnings & Insights
- Cool idea is to have a visualization of the type of questions that are asked
  - Is clustering even worth it? How many clusters?
- PII info for SBA queries are redacted but instead of de-indentification, the entire query is thrown away
  - An improvement is to have a de-identification process and keep the query to be used in the future
  - Ex. [help_center_chat_interaction_summary](https://data.shopify.io/details/gcp/bigquery/shopify-dw.support.help_center_chat_interaction_summary) - all queries past 30 days are [REDACTED](https://docs.google.com/spreadsheets/d/15vfSg2Vk2lSDJDIdMI8PCb4jY-ARVfFKebXyveGsnq4/edit?gid=799813372#gid=799813372)

## Challenges & Solutions
- Need to find some time to finish onboarding... so much things to do...

## Tomorrow's Plan
- Continue with findings doc
- Try and finish onboarding